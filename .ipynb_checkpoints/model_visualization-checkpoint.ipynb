{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Results Visualization\n",
    "This notebook is intended to pull model artifacts from the Neptune experiment logger and run it on a few samples from the dataset to see visualize how the different model's are segmenting the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune import Session\n",
    "import pickle\n",
    "from rasterio.plot import show\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torchvision\n",
    "import zipfile\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_types = ['full_channel', 'rgb', 'ir', 'hsv', 'hsv_with_ir', 'veg_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"image_samples.pkl\", \"rb\")\n",
    "image_samples = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create session and import my project\n",
    "sesh = Session.with_default_backend(api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5\"\n",
    "                                \"lcHR1bmUuYWkiLCJhcGlfa2V5IjoiOGE5NDI0YTktNmE2ZC00ZWZjLTlkMjAtNjNmMTIwM2Q2ZTQzIn0=\")\n",
    "project = sesh.get_project(\"maxzvyagin/GIS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = project.get_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = experiments[0]\n",
    "e.get_system_properties()\n",
    "e.get_logs()['test_loss']['y']\n",
    "e.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Unet:\n\tUnexpected key(s) in state_dict: \"classification_head.3.weight\", \"classification_head.3.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e8fafefa6ce5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# saving to variable to suppress huge printout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.5/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   1045\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Unet:\n\tUnexpected key(s) in state_dict: \"classification_head.3.weight\", \"classification_head.3.bias\". "
     ]
    }
   ],
   "source": [
    "for e in experiments:\n",
    "    id_num = int(e.get_system_properties()['id'].split('GIS-')[1])\n",
    "    #encoder = e.get_system_properties()['tags'][-1]\n",
    "#     if \"encoder\" in encoder:\n",
    "#         encoder = encoder.split(\"encoder\")[1].lower()\n",
    "#     else:\n",
    "#         encoder = encoder.lower()\n",
    "    if id_num == 448 and e.state == 'succeeded':\n",
    "        # load in the model\n",
    "        e.download_artifacts()\n",
    "        with zipfile.ZipFile('output.zip') as zip_ref:\n",
    "            zip_ref.extractall()\n",
    "        f = open('output/latest_model.pkl', 'rb')\n",
    "        device = torch.device('cpu')\n",
    "        old_params = torch.load(f, map_location=device)\n",
    "        params = dict()\n",
    "        i_type = e.get_parameters()['image_type']\n",
    "        if i_type == \"full_channel\":\n",
    "            input_num = 4\n",
    "        elif i_type == \"rgb\":\n",
    "            input_num = 3\n",
    "        elif i_type == \"ir\":\n",
    "            input_num = 1\n",
    "        elif i_type == \"hsv\":\n",
    "            input_num = 3\n",
    "        elif i_type == \"hsv_with_ir\":\n",
    "            input_num = 4\n",
    "        elif i_type == \"veg_index\":\n",
    "            input_num = 1\n",
    "        else:\n",
    "            input_num = 4\n",
    "        aux = dict(dropout=0.5, classes=1)\n",
    "        model = smp.Unet(classes=1, in_channels=4, aux_params=aux)\n",
    "        # fix the weird state dict key error\n",
    "        for k in old_params.keys():\n",
    "            new_key = k.split(\"model.\")[1]\n",
    "            params[new_key] = old_params[k]\n",
    "        # saving to variable to suppress huge printout\n",
    "        print(encoder)\n",
    "        y = model.load_state_dict(params)\n",
    "        f.close()\n",
    "        y = model.eval()\n",
    "        # check the image type, and get image samples for corresponding image type\n",
    "        # run the model on each of the samples and show results\n",
    "        # print experiment id, name, image type, and training/test loss\n",
    "        # print(e.get_properties(), e.get_numeric_channels_values())\n",
    "        # show mask, and then show the results from each \n",
    "        for test in image_samples[i_type]:\n",
    "            fig, (m_axis, i_axis) = pyplot.subplots(1, 2)\n",
    "            fig.suptitle(\"Experiment: \"+encoder+\", Test Loss: \"+e.get_logs()['test_loss']['y'], fontsize=16)\n",
    "            if i_type == \"veg_index\":\n",
    "                channel_input = test['image'].unsqueeze(0)\n",
    "                channel_input = channel_input.unsqueeze(1)\n",
    "                res = model(channel_input)\n",
    "            else:\n",
    "                res = model(test['image'].unsqueeze(0)).detach().numpy()\n",
    "            #res = torch.max(output[:, 0, :, :], output[:, 1, :, :])\n",
    "            res.squeeze(0)\n",
    "            res[res >= 0] = 1\n",
    "            res[res < 0] = 0\n",
    "            #res = np.rint(res.detach().numpy())\n",
    "#             res = torch.max(model(test['image'].unsqueeze(0)))\n",
    "            #res = np.reshape(res, (2, 256, 256))\n",
    "            print(res.shape) \n",
    "            #print(res[:10])\n",
    "            show(res, ax=i_axis, title=\"Model Prediction\")\n",
    "            show(test['mask'], ax=m_axis, title=\"Ground Truth\")\n",
    "            pyplot.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in experiments:\n",
    "    # load in the model\n",
    "    e.download_artifacts()\n",
    "    with zipfile.ZipFile('output.zip') as zip_ref:\n",
    "        zip_ref.extractall()\n",
    "    f = open('output/latest_model.pkl', 'rb')\n",
    "    device = torch.device('cpu')\n",
    "    old_params = torch.load(f, map_location=device)\n",
    "    params = dict()\n",
    "    i_type = e.get_parameters()['image_type']\n",
    "    if i_type == \"full_channel\":\n",
    "        input_num = 4\n",
    "    elif i_type == \"rgb\":\n",
    "        input_num = 3\n",
    "    elif i_type == \"ir\":\n",
    "        input_num = 1\n",
    "    elif i_type == \"hsv\":\n",
    "        input_num = 3\n",
    "    elif i_type == \"hsv_with_ir\":\n",
    "        input_num = 4\n",
    "    elif i_type == \"veg_index\":\n",
    "        input_num = 1\n",
    "    else:\n",
    "        i_type = 4\n",
    "    model =  torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', in_channels=input_num,\n",
    "                                    out_channels=1,\n",
    "                                    init_features=32, pretrained=False)\n",
    "    # fix the weird state dict key error\n",
    "    for k in old_params.keys():\n",
    "        new_key = k.split(\"model.\")[1]\n",
    "        params[new_key] = old_params[k]\n",
    "    model.load_state_dict(params)\n",
    "    f.close()\n",
    "    # check the image type, and get image samples for corresponding image type\n",
    "    # run the model on each of the samples and show results\n",
    "    # print experiment id, name, image type, and training/test loss\n",
    "    # print(e.get_properties(), e.get_numeric_channels_values())\n",
    "    # show mask, and then show the results from each \n",
    "    for test in image_samples[i_type]:\n",
    "        fig, (m_axis, i_axis) = pyplot.subplots(1, 2)\n",
    "        fig.suptitle(\"Experiment: \"+e.get_system_properties()['name']+\", Test Loss: \"+e.get_logs()['test_loss']['y'], fontsize=16)\n",
    "        if i_type == \"veg_index\":\n",
    "            channel_input = test['image'].unsqueeze(0)\n",
    "            channel_input = channel_input.unsqueeze(1)\n",
    "            res = model(channel_input)\n",
    "        else:\n",
    "            res = model(test['image'].unsqueeze(0))\n",
    "        res = np.rint(res.detach().numpy())\n",
    "        show(res, ax=i_axis, title=\"Model Prediction\")\n",
    "        show(test['mask'], ax=m_axis, title=\"Ground Truth\")\n",
    "        pyplot.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
